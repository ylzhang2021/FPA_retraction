\documentclass{article}
\usepackage{amsmath,amsfonts,verbatim,amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{color}
\oddsidemargin 0in
\textwidth 6.5in
\textheight=9in
\topmargin=-0.5in

\allowdisplaybreaks[3]
\newcommand{\rrev}[1]{{\color{blue}#1}}

\def\R{\mathbb{R}}

\begin{document}



\section*{Author's responses to Referee 1}
Thank you very much for reading the manuscript carefully and providing useful suggestions. To facilitate the review process, we have marked all our changed in blue.  The following is our response to your suggestions and comments.

\paragraph{Main comments:}
\begin{enumerate}
	\item  \textit{\textbf{Reviewer:}} \textit{P3, L42: The closed ball with respect to which norm?}
	
	\textbf{Response:} Thanks for the comment. The closed ball is with respect to the Euclidean norm. We have modified it accordingly.

	\item  \textit{\textbf{Reviewer:}} \textit{P4, L48-49: Please, give a reference for this assertion.}
	
	\textbf{Response:} {\color{red}{Unanswered.}}

	\item  \textit{\textbf{Reviewer:}} \textit{P5, Algorithm 1: It is not clear to me what is the role of parameter $\underline{\beta}$. Is it only used as a lower bound for the initial $\beta_k^0$? If so, how can you assert that $\inf_k \beta_k \ge \underline{\beta}$ in Remark 3.1? The same applies to Algorithm 2 and Remark 4.1.}
	
	\textbf{Response:} Thanks for the comment. Yes, $\underline{\beta}$ is used as a lower bound for the initial $\beta_k^0$. In Remark 3.1, we asserted that
\begin{equation}\label{infbeta}
\inf_k \beta_k \ge \beta_{\min}:= \textstyle\min\left\{\frac{\eta}{2}\left(\frac{c}2 + \frac{M_1L}{-2\max\limits_{1 \le i \le m}\{g_i(x^\odot)\}}\right)^{-1},\underline{\beta}\right\}.
\end{equation}
Indeed, from the proof of Theorem 3.1(iii), we see that the line search condition in Step 2b) will be satisfied as long as $\widetilde \beta \le \frac{1}{2}\left(\frac{c}2 + \frac{M_1L}{-2\max\limits_{1 \le i \le m}\{g_i(x^\odot)\}}\right)^{-1}$. By the definition of backtracking linesearch, if backtracking was invoked, it means that $\beta_k$ is accepted while $\eta^{-1}\beta_k$ was not accepted. Thus, it must hold that
\[
\eta^{-1}\beta_k > \frac{1}{2}\left(\frac{c}2 + \frac{M_1L}{-2\max\limits_{1 \le i \le m}\{g_i(x^\odot)\}}\right)^{-1}.
\]
Finally, we also need to consider the case that backtracking was not invoked at all: this happens when $\beta^0_k$ is already small enough. In this case, we make use of the lower bound $\underline{\beta}$ to conclude that $\beta_k \ge \underline{\beta}$. Overall, we get the lower bound as in \eqref{infbeta} above.
%
%In fact, if $\frac{\eta}{2}\left(\frac{c}2 + \frac{M_1L}{-2\max\limits_{1 \le i \le m}\{g_i(x^\odot)\}}\right)^{-1} > \underline{\beta}$, then $\beta_{min} = \underline{\beta}$, by the proof of Theorem~3.1(iii), we have the assert holds; if $\frac{\eta}{2}\left(\frac{c}2 + \frac{M_1L}{-2\max\limits_{1 \le i \le m}\{g_i(x^\odot)\}}\right)^{-1} < \underline{\beta}$, the assert is clearly valid. The same applies to Remark 4.1.

	\item  \textit{\textbf{Reviewer:}} \textit{P7, L23: I cannot see how [38, Th 2.6] is applied (same doubt in Theorem 4.1, P16 L9). Are you assuming full domain of functions P1 and P2? If so, make it more explicit.}
	
	\textbf{Response:} Thanks for the comment. We assume that $P_1:\R^n\rightarrow\R$ and $P_2:\R^n\rightarrow\R$ are continuous convex functions, which were assumed at the beginning of the article.

	\item  \textit{\textbf{Reviewer:}} \textit{P8, L43: Why is $\xi^k$ bounded? Maybe this it related with the full domain asked in item 4. The same for $\partial P_1(u^{k_j})$.}
	
	\textbf{Response:} Thanks for the comment. We assume that $P_1:\R^n\rightarrow\R$ and $P_2:\R^n\rightarrow\R$ are continuous convex functions at the beginning of the article.

	\item  \textit{\textbf{Reviewer:}} \textit{P10, L10: How does one get the term $+\frac{1}{\beta_k}\|u^k - x^k\|^2$? It is supposed that the authors are using the convexity of P1, but it is not strongly convex.}
	
	\textbf{Response:} Thanks for the comment. It is only need the convexity of $P_1$. In fact, it contain two steps, we first use the convexity of $P_1$, then according to the nonnegative of $+\frac{1}{\beta_k}\|u^k - x^k\|^2$, we get it, i.e.,
\[
P_1(x^{k+1})\leq P_1(u^k) + \tau_k(P_1(x^\odot) - P_1(u^k))\leq P_1(u^k) + \tau_k(P_1(x^\odot) - P_1(u^k)) + \frac{1}{2\beta_k}\|u^k - x^k\|^2.
\]

	\item  \textit{\textbf{Reviewer:}} \textit{P16, L29: Which is the closed form formula for $\tilde{\tau}$?}
	
	\textbf{Response:} Thanks for the comment. By the definition of $\ell^{y}(u)$ in (4.4), we have that
\begin{equation*}
\begin{aligned}
\ell^{x^k}(A((1-\widetilde\tau)\widetilde u + \widetilde\tau x^\circledcirc) - b) &= \sum_{i=1}^p\varphi_+'\big((a_i^T x^k - b_i)^2\big)(A((1-\widetilde\tau)\widetilde u + \widetilde\tau x^\circledcirc) - b)_i^2\\
& = \sum_{i=1}^p\varphi_+'\big((a_i^T x^k - b_i)^2\big)((\widetilde\tau A(x^\circledcirc - \widetilde u))^2 + 2\widetilde\tau A(x^\circledcirc - \widetilde u)(A\widetilde u - b) + (A\widetilde u - b)^2)_i\\
&= \widetilde\tau^2(\sum_{i=1}^p\varphi_+'\big((a_i^T x^k - b_i)^2\big)(A(x^\circledcirc - \widetilde u))_i^2) \\
&~~~~+ 2\widetilde\tau (\sum_{i=1}^p\varphi_+'\big((a_i^T x^k - b_i)^2\big)(A(x^\circledcirc - \widetilde u)(A\widetilde u - b))_i) \\
&~~~~+ \sum_{i=1}^p\varphi_+'\big((a_i^T x^k - b_i)^2\big)(A\widetilde u - b)^2_i,
\end{aligned}
\end{equation*}
which is a quadratic function in $\widetilde\tau$. Therefore, from $\ell^{x^k}(A((1-\widetilde\tau)\widetilde u + \widetilde\tau x^\circledcirc) - b) = \tilde{\sigma}^{x^k}$, $\widetilde\tau$ admits a closed form formula.
	\item  \textit{\textbf{Reviewer:}} \textit{P23, L44: How is such $\tau$ found?}
	
	\textbf{Response:} Thanks for the comment. In fact,
\begin{equation*}
\begin{aligned}
\sigma^2 &= \|A(\widehat x_{\rm spgl1} + \tau(A^\dagger b - \widehat x_{\rm spgl1})) - b\|^2\\
 &=\tau^2\|A(A^\dagger b - \widehat x_{\rm spgl1})\|^2 + 2\tau\|A(A^\dagger b - \widehat x_{\rm spgl1})\|\|A(\widehat x_{\rm spgl1} - b\| + \|A(\widehat x_{\rm spgl1} - b\|^2
\end{aligned}
\end{equation*}
which is a quadratic function in $\tau$. It is easy to calculate $\tau$.


	\item  \textit{\textbf{Reviewer:}} \textit{Numerical results: As far as I see, Algorithm 3 does not require to find a completely feasible initial point ($x_0\in F$) but just in C ($x_0\in C$). I did not find any statement about how the initial point is chosen for ESQM$_{\rm ls}$. In principle, SPGL1 and Slater point are not needed. Therefore, it is not fair to say that FPA is faster since the sum of the iteration time plus the required initialization exceeds the CPU time of ESQM$_{\rm ls}$. Would it be any other cheaper way to compute $x_0$?}
	
	\textbf{Response:} {\color{red}{Unanswered.}}

    \item  \textit{\textbf{Reviewer:}} \textit{P26: In table 2, the time of SPGL1 for i = 4 is greater than for i = 6. Does it make any sense?}
	
	\textbf{Response:} Thanks for this nice point. We double checked and found that the codes are correct. The results in table 2 are the average based on 30 randomly generating instances. When $i = 4$, it seems that two sets of data take exceptionally more time, so it appears that SPGL1 takes more time in the case $i = 4$ than in the case $i = 6$.

    \item  \textit{\textbf{Reviewer:}} \textit{References: It seems that there exists a more recent version (2016) of [38]. Update [43] and all the referenced results from there to its published version (SIAM J. Optim., 31(3), 2024--2054.).}
	
	\textbf{Response:} Thanks for the comment. We have modified it according to this suggestion.






\end{enumerate}


\section*{Author's responses to Referee 2}
Thank you very much for reading the manuscript carefully and providing useful suggestions. The following is our response to your suggestions and comments one by one.
%To facilitate the review process, we have marked all our changed in blue.

\paragraph{Main comments:}
\begin{enumerate}
   \item \textit{\textbf{Reviewer:}} {\it The retraction strategy employed by the authors is nothing but an interpolation step, already present in the Support Hyperplane Method (SHM) by Veinott (1967) (see reference [A]). Moreover, in contrast to the setting of the proposed Algorithm 1, the work [A] (and more recently its regularized version in [B]) does not require the constraint function(s) to be convex, but the feasible set. This weaker assumption allows the nonlinear constraint function to have only generalized convexity properties (e.g., quasi-convexity, alpha-convexity [B]). That being said, we believe it is possible to weaken the convexity assumption on the constraint functions in Algorithm 1 with only a few modifications in the convergence analysis. Could the authors confirm that?
       
       Apart from the interpolation step, what are the main differences between the proposed methodologies and paper [42]?
       
Although Algorithm 1 employs the SHM's interpolation step, it differs substantially from SHM due to the DC structure. However, Algorithm 1, as well as Algorithm 2, handle the DC structure similarly to the Proximal Linearized Method for DC programming [C,D,E]: at every iteration, the concave part is linearized, and a quadratic term is added to form the objective function in the convex subproblem. In particular, the method in [E] seems more general than Algorithms 1 and 2 because the former allows for DC-constrained DC programs. Therefore, we kindly ask the authors to put their methodology in perspective with [E].

That being said, we see the methodology presented in this manuscript as a "linearized proximal method with support hyperplane for DC programs."
Indeed, the above seems a better title for the work because it connects the core ideas in the manuscript.}

    \textbf{Response:} Thanks for the comment. 
    
    {\it Difference from [A,B]}: We would like to point out that our method is {\it significantly different} from the one in [A,B]. Indeed, [A,B] employs a cutting plane strategy. In particular, as the algorithm progresses, the number of halfspaces involved in the subproblem {\em grows}, with many of them constructed based on information from the \emph{past iterates}. They exploited the fact that compact convex sets can be written as the intersection of (infinitely many) halfspaces, and deduced convergence based on this {\em without} requiring any descent property of the (interpolated) sequence generated.
    
    In contrast, our method only requires a {\it fixed} number of halfspaces in each iteration, and the constraint functions are linearized only at the \emph{current iterate}. Thus, the computational effort for solving each subproblem is similar. Moreover, we have to sufficiently regularize the objective of our subproblem so that our retraction (or interpolation) step induces a descent: this is an ingredient not present in the method in [A,B] because their convergence is based on the fact that the intersection of the \emph{growing} number of halfspaces constructed in their algorithm converges to the original feasible set.
    
    {\it Difference from [42]}: Apart from the retraction step, the key difference is that we are using linear approximations to the constraint functions in the subproblems, while the method in [42] is based on quadratic \emph{majorants} of the constraint functions. Thus, one obtains a feasible point by solving the subproblems in the algorithm in [42], but one does not necessarily obtain a feasible point by solving the subproblem in the FPA method: hence, a retraction step kicks in to restore feasibility. Finally, as mentioned in footnote 1 on page 2, our subproblems based on linear approximations are potentially simpler to solve than those quadratically constrained subproblems in [42].
    
    {\it Difference from [C,D]:} The algorithms proposed in these papers do not seem to use any approximation to the constraint set or exploit the explicit form of the constraint functions.
    
    {\it Difference from [E]:} The most closely related algorithm is algorithm 2 in [E]. In this algorithm, the DC constraint function is replaced a convex majorant. In spirit, this is similar to what is done in standard DCA (similar to, for example, [42]), and is different from our algorithm as discussed above. Moreover, the algorithm in [E] constructs subproblems by including only constraints that are approximately ``active". This is an ingredient not considered in our algorithm and it is an interesting future research direction as a possible strategy for constructing simpler subproblems for our algorithm.
    
    Finally, after looking at [A,B] kindly suggested by the reviewer, we feel that the term ``support hyperplane method" typically reminds the readers of cutting plane strategy, which usually involves a {\em growing number of} halfspaces constructed from the current and {\em previous iterates}. Our method, in contrast, involves a {\em fixed} number of halfspaces constructed via linear approximating the constraint functions at the current iterate. Thus, we believe that it is better not to mention supporting hyperplane in the title. Keep the current title may be appropriate.
    
    \item \textit{\textbf{Reviewer:}} {\it The assumptions are poorly stated. For instance, Assumption 3.1 (announced in the key Theorems 3.1 and 3.2) asserts that $g_i$ is convex and a Slater point exists. However, the authors need much more than this: $g_i$ needs to be differentiable (rightly stated in the proofs and other parts), and the Slater point must be known. Note that knowing a Slater point is much more restrictive than only assuming its existence. We kindly ask the authors to fix this issue.}
        
    \textbf{Response:} Thanks for the comment. We believe that there could be some misunderstanding.
    
    Indeed, we have made it clear right after stating model (1.1) that there are differentiability assumptions on $g_i$ (which unfortunately went into page 2 and probably got unnoticed). We have been referring to model problem (1.1) in all our assumptions and theorems, which should be sufficient to indicate that we are assuming all conditions stated right after (1.1) for $P_1$, $P_2$, $g_i$ and $C$.

	\item \textit{\textbf{Reviewer:}} \textit{ a) In the Introduction, the authors related their methodology with Sequential Quadratic Programming. However, this link is unclear since this manuscript deals with nonsmooth DC programs, and SQP is for (twice) differentiable problems. Could the authors please give more details on such a connection? Is it related to the sequential DC programming ideas from [F]?}
	
	\textbf{Response:} Thanks for the comment.

    A key common feature between our method and SQP-type method lies in the way the constraint set is dealt with. In both methods, the constraint functions are replaced by linear approximations and feasibility to the original problem is not guaranteed by solving the subproblems. Our key innovation is to further incorporate the ``retract" idea from manifold optimization to create a feasible next iterate.
    
    As for the sequential DC programming method the reviewer suggested, it appears to us that the constraint set is fixed for all iterations. Thus, it is different from our method which is constructing successive polyhedral approximation to the feasible set.
	
	\item \textit{\textbf{Reviewer:}} \textit{ b) As far as we can tell, Definition 2.3 is about criticality and not stationarity. Stationarity in DC programming is a strong condition, and most algorithms are only ensured to compute critical points. Please see [E] for the differences between these two conditions.}
	
	\textbf{Response:} Thanks for the comment. We agree with this comment. We changed all ``stationary points" to ``critical points". See, for example, Definition 2.3.
	
	\item  \textit{\textbf{Reviewer:}} \textit{ c) Theorem 3.2. Please recall that $u^k = \tilde u$.}
	
	\textbf{Response:} Thanks for the comment. We added that the sequence $\{u^k\}$ is generated by the algorithm 1 and $u^k = \tilde u$ in the statement of the theorem.

	\item \textit{\textbf{Reviewer:}} \textit{ d) Assumption 4.1. The notation $\xi$ has already been employed for the subgradient of $P_2$.}

    \textbf{Response:} Thanks for the comment. We replace $\xi$ with $\varphi$ in Assumption 4.1 and beyond.

	\item \textit{\textbf{Reviewer:}} \textit{ e) Assumption 4.2. The Slater point must be known.}

    \textbf{Response:} Thanks for the comment. We definitely agree that the Slater point must be known. We modified Assumption 3.1 and 4.2.

	\item \textit{\textbf{Reviewer:}} \textit{ f) Subproblem (4.6): Should it be $\sigma^x$?}

    \textbf{Response:} Thanks for the comment. It should be $\sigma$ in subproblem (4.6). Indeed, in view of Lemma 4.1(iv), one can see that the inequality constraint in (4.6) is the same as
    \[
    \ell^{x^k}(Ax^k - b) + \langle A^T\nabla \ell^{x^k}(Ax^k - b),x-x^k\rangle \le \tilde \sigma^{x^k}.
    \]

	\item \textit{\textbf{Reviewer:}} \textit{ g) Please compare the algorithms with the method presented in [42], by the third author.}

    \textbf{Response:} {\color{red}{Unanswered.}}
\end{enumerate}


\end{document}
